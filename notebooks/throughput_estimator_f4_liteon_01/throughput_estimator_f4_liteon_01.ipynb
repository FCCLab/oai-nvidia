{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2499156c-144f-45f2-b337-30f4643f19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check platform.\n",
    "import platform\n",
    "if platform.machine() not in ['x86_64', 'aarch64']:\n",
    "    raise SystemExit(\"Unsupported platform!\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the channel estimator and some utilities for converting\n",
    "# the DMRS fields in the right format from the SCF FAPI format that the dataset follows.\n",
    "from aerial.phy5g.algorithms import ChannelEstimator\n",
    "from aerial.util.fapi import dmrs_fapi_to_bit_array\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# !pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "# Connecting to clickhouse on remote server\n",
    "import clickhouse_connect\n",
    "clickhouse_client = clickhouse_connect.get_client(host='localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ecf3d5e-040a-4189-97ce-2d09061c2276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())  # Number of GPUs available\n",
    "device = torch.device(\"cuda:0\")  # Select the first GPU (index 0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6109d9-81cb-4359-83f3-24219fcd7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "model = torch.load(\"model_w10_i4_o1_h50_l1.pth\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb743c0-1134-43fa-a2de-a737cef23164",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cd82b8-53dd-4c3f-b237-9fff6b892c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LSTM                                     [1]                       --\n",
      "├─LSTM: 1-1                              [1, 10, 50]               11,200\n",
      "├─Sequential: 1-2                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 1]                    51\n",
      "==========================================================================================\n",
      "Total params: 11,251\n",
      "Trainable params: 11,251\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.11\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_stats = summary(model, input_size=(1, WINDOWS_SIZE, 4))\n",
    "print(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732563fe-4b97-4931-85e5-8d79bab1f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n",
      " 2025-04-11 10:19:26.412000: 37.44750213623047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model(X_torch\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM MAC_KPIs \n",
    "    ORDER BY TsTaiNs DESC\n",
    "    LIMIT {WINDOWS_SIZE}\n",
    "    \"\"\"\n",
    "    # print(query)\n",
    "    kpis = clickhouse_client.query_df(query)\n",
    "    # print(kpis)\n",
    "\n",
    "    x = kpis[['phr', 'wb_cqi', 'pusch_snr', 'rsrp']].to_numpy() / np.array([100, 20, 30, -150])\n",
    "    timestamp = kpis['TsTaiNs'].iloc[-1]\n",
    "\n",
    "    X_torch = torch.tensor([x], dtype=torch.float32)\n",
    "    predicted = model(X_torch.to(device)).to(\"cpu\").detach().numpy()\n",
    "    print(f\" {timestamp}: {predicted[-1]}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bf722-5e12-4baa-a8db-832a814876db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
